#!/usr/bin/env node
/**
 * Routing Display Hook â€” PostToolUse
 * v5.4: last-call.json ê¸°ë°˜ ë¼ìš°íŒ… ì •ë³´ ë°•ìŠ¤ ì¶œë ¥
 *
 * MCP multi-model-agent ë„êµ¬ í˜¸ì¶œ í›„ ë¼ìš°íŒ… ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
 * Claude Codeì˜ hook íŒŒì´í”„ëŠ” ANSIë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ìœ ë‹ˆì½”ë“œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
 * ë“±ë¡: settings.json PostToolUse â€” matcher: "mcp__multi-model-agent"
 */

import { readFileSync, existsSync } from "fs";
import { homedir } from "os";
import { join } from "path";

const BASE           = join(homedir(), "mcp-servers", "multi-model");
const LAST_CALL_PATH = join(BASE, "last-call.json");

const MODEL_DISPLAY = {
  "gpt-5.3-codex": "GPT-5.3-Codex",
  "glm-5":         "GLM-5",
  "parallel":      "All Models",
};

const MODEL_ICON = {
  "gpt-5.3-codex": "ğŸ§ ",
  "glm-5":         "âš¡",
  "parallel":      "ğŸ”€",
};

const CATEGORY_ICON = {
  ultrabrain: "ğŸ›",
  deep:       "ğŸ”¬",
  visual:     "ğŸ¨",
  research:   "ğŸ“š",
  bulk:       "âš™ï¸",
  writing:    "âœï¸",
  quick:      "âš¡",
};

// â”€â”€â”€ stdin ì½ê¸° (for await íŒ¨í„´ â€” Windows í˜¸í™˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const chunks = [];
for await (const chunk of process.stdin) chunks.push(chunk);

const raw = Buffer.concat(chunks).toString("utf8").trim();
if (!raw) process.exit(0);

let input;
try { input = JSON.parse(raw); } catch { process.exit(0); }

const toolName = input?.tool_name ?? input?.tool ?? input?.tool_use?.name ?? "";
if (!toolName.includes("multi-model-agent")) process.exit(0);

const tool = toolName.split("__").pop();
if (tool === "get_usage_stats") process.exit(0);

// â”€â”€â”€ last-call.json ì½ê¸° (index.jsê°€ ì‘ì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if (!existsSync(LAST_CALL_PATH)) process.exit(0);

let meta;
try { meta = JSON.parse(readFileSync(LAST_CALL_PATH, "utf8")); } catch { process.exit(0); }

// 30ì´ˆ ì´ë‚´ ê¸°ë¡ë§Œ ì‹ ë¢° (xhigh reasoningì€ í›… ë”œë ˆì´ê°€ í´ ìˆ˜ ìˆìŒ)
if (meta.timestamp && Date.now() - new Date(meta.timestamp).getTime() > 30000) process.exit(0);

// â”€â”€â”€ ê²½ê³¼ì‹œê°„ ê³„ì‚° (ì„œë²„ ì¸¡ elapsed_ms ì‚¬ìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const elapsedSec = meta.elapsed_ms ? (meta.elapsed_ms / 1000).toFixed(1) : null;
const statusIcon = meta.status === "error" ? "âŒ" : "âœ…";

// â”€â”€â”€ ì¶œë ¥ êµ¬ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const modelKey  = meta.model ?? "unknown";
const modelIcon = MODEL_ICON[modelKey] ?? "ğŸ¤–";
const modelName = MODEL_DISPLAY[modelKey] ?? modelKey;
const effortStr = meta.reasoning_effort && meta.reasoning_effort !== "none"
  ? ` Â· reasoning:${meta.reasoning_effort}` : "";
const catIcon = meta.category ? (CATEGORY_ICON[meta.category] ?? "ğŸ“Œ") : "";
const elapsedStr = elapsedSec ? ` Â· ${elapsedSec}s` : "";

// ë°•ìŠ¤ ë„ˆë¹„ ê³ ì • (ì´ëª¨ì§€ í­ ê³ ë ¤ ì—†ì´ ASCIIë§Œìœ¼ë¡œ êµ¬ì„±)
const BOX_WIDTH = 58;
const lines = [`â”Œâ”€ ROUTING ${statusIcon}${"â”€".repeat(BOX_WIDTH - 12)}`];

if (tool === "ask_parallel" || modelKey === "parallel") {
  const modelList = (meta.models ?? ["gpt", "glm"])
    .map((m) => {
      const key = m === "gpt" ? "gpt-5.3-codex" : m === "glm" ? "glm-5" : m;
      return `${MODEL_ICON[key] ?? "ğŸ¤–"} ${MODEL_DISPLAY[key] ?? m}`;
    })
    .join("  +  ");
  lines.push(`â”‚  ğŸ”€ Parallel: ${modelList}${elapsedStr}`);
} else {
  lines.push(`â”‚  ${modelIcon} ${modelName}${effortStr}${elapsedStr}`);
  if (meta.category) lines.push(`â”‚  ${catIcon} ${meta.category}`);
  if (meta.routing && meta.routing.includes("fail")) lines.push(`â”‚  âš   í´ë°± ë°œìƒ`);
}

lines.push(`â””${"â”€".repeat(BOX_WIDTH)}`);

process.stdout.write(lines.join("\n") + "\n");
